{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final | Analytics Engineering\n",
    "----\n",
    "**Engenharia de Dados e Garantia de Qualidade no Conjunto de Dados do Airbnb no Rio de Janeiro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1:\n",
    "\n",
    "**Aquisição de Dados e Armazenamento de Dados em PostgreSQL - Camada Bronze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Baixe o conjunto de dados \"Inside Airbnb\" do Rio de Janeiro da fonte oficial (http://insideairbnb.com/) e promova uma estruturação simples nos dados.\n",
    "   - Crie um banco de dados PostgreSQL para armazenar os dados brutos das 3 tabelas (\"Listing\", \"Reviews\" e Calendar\") na camada \"bronze\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text as sql_text\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar modulo de conexão e implementação do banco  \n",
    "import modules.database_connection_os as db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada da biblioteca para usar o SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy Streamlit apps for free on Ploomber Cloud! Learn more: https://ploomber.io/s/signup\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações do banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estabelecer uma conexão com um banco de dados PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar conexão\n",
    "engine = db.engine_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão bem sucedida!\n"
     ]
    }
   ],
   "source": [
    "# Testar a conexão\n",
    "try:\n",
    "    with engine.connect():\n",
    "        print(\"Conexão bem sucedida!\")\n",
    "except Exception as e:\n",
    "    print(\"Erro ao conectar:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar schemas do banco de dados PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Schema 'bronze' ja existe.\n",
      "O Schema 'silver' ja existe.\n",
      "O Schema 'gold' ja existe.\n"
     ]
    }
   ],
   "source": [
    "db.criar_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Bronze - Ingestão e Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dados/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar tabelas no Banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tabela Listing\n",
    "\n",
    "df_listings = pd.read_csv(path + 'listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando a tabela 'listings' no schema 'bronze'....\n",
      "A tabela 'listings' foi criada no schema 'bronze', e os dados foram inseridos.\n"
     ]
    }
   ],
   "source": [
    "# Criar e salvar o DataFrame na tabela \"listings\" dentro do esquema \"bronze\"\n",
    "db.criar_tabela_df('bronze', 'listings', df_listings,'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tabela Reviews\n",
    "\n",
    "df_reviews = pd.read_csv(path + 'reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando a tabela 'reviews' no schema 'bronze'....\n",
      "A tabela 'reviews' foi criada no schema 'bronze', e os dados foram inseridos.\n"
     ]
    }
   ],
   "source": [
    "# Criar e salvar o DataFrame na tabela \"reviews\" dentro do esquema \"bronze\"\n",
    "db.criar_tabela_df('bronze', 'reviews', df_reviews,'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tabela Calendar\n",
    "\n",
    "df_calendar = pd.read_csv(path + 'calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando a tabela 'calendar' no schema 'bronze'....\n",
      "A tabela 'calendar' foi criada no schema 'bronze', e os dados foram inseridos.\n"
     ]
    }
   ],
   "source": [
    "# Criar e salvar o DataFrame na tabela \"calendar\" dentro do esquema \"bronze\"\n",
    "db.criar_tabela_df('bronze', 'calendar', df_calendar,'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2:\n",
    "\n",
    "**Data Clean - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Identifique e lide com valores ausentes, duplicatas e outliers nos dados brutos da camada \"bronze\".\n",
    "   - Padronize e limpe os nomes das colunas, convertendo-os em um formato consistente.\n",
    "   - Realize uma limpeza textual em campos, como descrições de propriedades, removendo caracteres especiais e erros de digitação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Silver - Limpeza de Dados e Criação de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das tabelas bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM bronze.listings\n",
    "\"\"\"\n",
    "df_silver_listings = pd.read_sql(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM bronze.reviews\n",
    "\"\"\"\n",
    "df_silver_reviews = pd.read_sql(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM bronze.calendar\n",
    "\"\"\"\n",
    "df_silver_calendar = pd.read_sql(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório com informações do perfil dos dados a partir da biblioteca \"ydata_profiling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profiling(df, df_name, output_file=None):\n",
    "    from ydata_profiling import ProfileReport\n",
    "\n",
    "    title = \"Profiling Report - \" + df_name\n",
    "    filename = output_file + df_name + \"_report.html\"\n",
    "\n",
    "    # criar relatório\n",
    "    profile = ProfileReport(df, title= title) \n",
    "\n",
    "    # salvar resultados em um arquivo\n",
    "    profile.to_file(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74928ee3f5b48f2aab4044f071bf714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 't'')\n",
      "  warnings.warn(\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\matrix.py:260: FutureWarning: Format strings passed to MaskedConstant are ignored, but in future may error or produce different behavior\n",
      "  annotation = (\"{:\" + self.fmt + \"}\").format(val)\n",
      "c:\\Users\\luana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ydata_profiling\\model\\missing.py:78: UserWarning: There was an attempt to generate the Heatmap missing values diagrams, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(missing_diagrams={\"Heatmap\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: '--'')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076adb48f81d466da30c34631d6d8ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e99df9a18142c2a9bd18c74032b53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51c220830444cddad24d90a3dd255ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_profiling(df_silver_listings, 'listings', 'data_profiling/')\n",
    "# data_profiling(df_silver_reviews, 'reviews', 'data_profiling/')\n",
    "# data_profiling(df_silver_calendar, 'calendar', 'data_profiling/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar e lidar com valores ausentes, duplicatas e outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, df_name):\n",
    "\n",
    "    print('Analisando a tabela ' + df_name + '\\n')\n",
    "\n",
    "    # Remover colunas com valores ausentes\n",
    "\n",
    "    cols_df = df.columns\n",
    "\n",
    "    print(\"Removendo colunas que possuem 100% de valores faltantes ...\")\n",
    "    df_cln = df.dropna(axis=1, how='all')\n",
    "\n",
    "    cols_df_cln = df_cln.columns\n",
    "    cols_removed = list(set(cols_df) - set(cols_df_cln))\n",
    "\n",
    "    print('Colunas removidas da tabela ', df_name, ': \\n', cols_removed)\n",
    "\n",
    "\n",
    "    # Remover campos duplicados\n",
    "    df_len = len(df_cln)\n",
    "\n",
    "    print(\"\\nRemovendo dados duplicados ...\")\n",
    "\n",
    "    df_cln = df_cln.drop_duplicates()\n",
    "\n",
    "    dup_lines = len(df_cln) - df_len\n",
    "\n",
    "    print('Foram removidas ', dup_lines, 'linhas da tabela ' + df_name)\n",
    "\n",
    "\n",
    "    # Remover colunas constantes (opcional)\n",
    "    print(\"\\nRemovendo colunas constantes ...\")\n",
    "\n",
    "    list_constant = [col for col in df_cln.columns if df_cln[col].nunique() == 1]\n",
    "    df_cln = df_cln.drop(list_constant, axis=1)\n",
    "\n",
    "    print('Colunas constantes removidas da tabela ' + df_name + ': \\n', list_constant)\n",
    "\n",
    "    return df_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, cols_list):\n",
    "    \"\"\"\n",
    "    Remover outliers de colunas específicas. Considera-se outliers em colunas numéricas \n",
    "    selecionadas com valor acima ou abaixo de 2 desvios padrão da média.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: dataframe\n",
    "        Dataframe processado.\n",
    "        \n",
    "    cols_list: list\n",
    "        Lista de colunas para considerar a eliminação de outliers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: dataframe\n",
    "        Dataframe sem outliers.\n",
    "\n",
    "    \"\"\"\n",
    "    qtd_lines = len(df)\n",
    "\n",
    "    df_aux = df.copy()\n",
    "    for col in cols_list:\n",
    "        low_limit = df_aux[col].quantile(.02) \n",
    "        high_limit = df_aux[col].quantile(.98) \n",
    "\n",
    "        df = df[(df[col]>low_limit) & (df[col]<high_limit)] \n",
    "\n",
    "    qtd_lines = qtd_lines - len(df)\n",
    "\n",
    "    print(\"\\nQuantidade de linhas (outliers) eliminadas: \", qtd_lines )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisando a tabela listings\n",
      "\n",
      "Removendo colunas que possuem 100% de valores faltantes ...\n",
      "Colunas removidas da tabela  listings : \n",
      " ['description', 'bedrooms', 'license', 'neighbourhood_group_cleansed', 'bathrooms', 'calendar_updated']\n",
      "\n",
      "Removendo dados duplicados ...\n",
      "Foram removidas  0 linhas da tabela listings\n",
      "\n",
      "Removendo colunas constantes ...\n",
      "Colunas constantes removidas da tabela listings: \n",
      " ['scrape_id', 'amenities']\n",
      "\n",
      "Quantidade de linhas (outliers) eliminadas:  27265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_url</th>\n",
       "      <th>host_name</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17878</td>\n",
       "      <td>https://www.airbnb.com/rooms/17878</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Condo in Rio de Janeiro · ★4.70 · 2 bedrooms ·...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>https://a0.muscache.com/pictures/65320518/3069...</td>\n",
       "      <td>68997</td>\n",
       "      <td>https://www.airbnb.com/users/show/68997</td>\n",
       "      <td>Matthias</td>\n",
       "      <td>...</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.67</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25026</td>\n",
       "      <td>https://www.airbnb.com/rooms/25026</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Rental unit in Rio de Janeiro · ★4.72 · 1 bedr...</td>\n",
       "      <td>Copacabana is a lively neighborhood and the ap...</td>\n",
       "      <td>https://a0.muscache.com/pictures/a745aa21-b8dd...</td>\n",
       "      <td>102840</td>\n",
       "      <td>https://www.airbnb.com/users/show/102840</td>\n",
       "      <td>Viviane</td>\n",
       "      <td>...</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.60</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         listing_url last_scraped       source  \\\n",
       "0  17878  https://www.airbnb.com/rooms/17878   2023-12-27  city scrape   \n",
       "1  25026  https://www.airbnb.com/rooms/25026   2023-12-27  city scrape   \n",
       "\n",
       "                                                name  \\\n",
       "0  Condo in Rio de Janeiro · ★4.70 · 2 bedrooms ·...   \n",
       "1  Rental unit in Rio de Janeiro · ★4.72 · 1 bedr...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0  This is the one of the bests spots in Rio. Bec...   \n",
       "1  Copacabana is a lively neighborhood and the ap...   \n",
       "\n",
       "                                         picture_url  host_id  \\\n",
       "0  https://a0.muscache.com/pictures/65320518/3069...    68997   \n",
       "1  https://a0.muscache.com/pictures/a745aa21-b8dd...   102840   \n",
       "\n",
       "                                   host_url host_name  ...  \\\n",
       "0   https://www.airbnb.com/users/show/68997  Matthias  ...   \n",
       "1  https://www.airbnb.com/users/show/102840   Viviane  ...   \n",
       "\n",
       "  review_scores_checkin review_scores_communication review_scores_location  \\\n",
       "0                  4.83                        4.91                   4.77   \n",
       "1                  4.81                        4.92                   4.84   \n",
       "\n",
       "  review_scores_value instant_bookable calculated_host_listings_count  \\\n",
       "0                4.67                f                              1   \n",
       "1                4.60                f                              1   \n",
       "\n",
       "  calculated_host_listings_count_entire_homes  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              1.90  \n",
       "1                                           0              1.67  \n",
       "\n",
       "[2 rows x 67 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Teste funções: process_dataframe e remove_outliers \n",
    "df_tst = df_silver_listings\n",
    "df_name = 'listings'\n",
    "\n",
    "df = process_dataframe(df_tst, df_name)\n",
    "\n",
    "cols_list = ['review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "df = remove_outliers(df, cols_list)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listings\n",
      "Analisando a tabela listings\n",
      "\n",
      "Removendo colunas que possuem 100% de valores faltantes ...\n",
      "Colunas removidas da tabela  listings : \n",
      " ['description', 'bedrooms', 'license', 'neighbourhood_group_cleansed', 'bathrooms', 'calendar_updated']\n",
      "\n",
      "Removendo dados duplicados ...\n",
      "Foram removidas  0 linhas da tabela listings\n",
      "\n",
      "Removendo colunas constantes ...\n",
      "Colunas constantes removidas da tabela listings: \n",
      " ['scrape_id', 'amenities']\n",
      "\n",
      "Quantidade de linhas (outliers) eliminadas:  27265\n"
     ]
    }
   ],
   "source": [
    "## Aplicar processamento em todas as tabelas silver\n",
    "\n",
    "# colunas para considerar a eliminação de outliers\n",
    "cols_listings = ['review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "cols_reviews = []\n",
    "cols_calendar = []\n",
    "\n",
    "# tabela listings\n",
    "df_process = process_dataframe(df_silver_listings, 'listings')\n",
    "df_silver_listings = remove_outliers(df_process, cols_listings)\n",
    "\n",
    "# tabela reviews\n",
    "df_process = process_dataframe(df_silver_reviews, 'reviews')\n",
    "df_silver_reviews = remove_outliers(df_process, cols_reviews)\n",
    "\n",
    "# tabela calendar\n",
    "df_process = process_dataframe(df_silver_calendar, 'calendar')\n",
    "df_silver_calendar = remove_outliers(df_process, cols_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisando a tabela listings\n",
      "\n",
      "Removendo colunas que possuem 100% de valores faltantes ...\n",
      "Colunas removidas da tabela  listings : \n",
      " ['description', 'bedrooms', 'license', 'neighbourhood_group_cleansed', 'bathrooms', 'calendar_updated']\n",
      "\n",
      "Removendo dados duplicados ...\n",
      "Foram removidas  0 linhas da tabela listings\n",
      "\n",
      "Removendo colunas constantes ...\n",
      "Colunas constantes removidas da tabela listings: \n",
      " ['scrape_id', 'amenities']\n",
      "\n",
      "Quantidade de linhas (outliers) eliminadas:  27265\n"
     ]
    }
   ],
   "source": [
    "## Aplicar processamento em todas as tabelas silver\n",
    "\n",
    "# colunas para considerar a eliminação de outliers\n",
    "# cols_listings = ['review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "# cols_calendar = []\n",
    "# cols_reviews = []\n",
    "\n",
    "# dict_tables = {'listings': [df_silver_listings, cols_listings],\n",
    "#                'calendar': [df_silver_calendar, cols_calendar],\n",
    "#                'reviews': [df_silver_reviews, cols_reviews]             \n",
    "#                }\n",
    "\n",
    "# for df_name, df_cols_list in dict_tables.items():\n",
    "\n",
    "#     df = df_cols_list[0]\n",
    "#     cols_list = df_cols_list[1]\n",
    "\n",
    "#     df_process = process_dataframe(df, df_name)\n",
    "#     df = remove_outliers(df_process, cols_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos nomes e tipos das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definir o tipo das colunas que não serão de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza textual dos campos (remoção de caracteres especiais e erros de digitação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3:\n",
    "\n",
    "**Data Quality - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Defina métricas de qualidade de dados, como integridade, precisão e consistência para os dados da camada \"bronze\".\n",
    "   - Implemente verificações para garantir que os dados da camada \"silver\" estejam em conformidade com essas métricas.\n",
    "   - Estabeleça um sistema de monitoramento contínuo da qualidade dos dados da camada \"silver\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação da precisão dos dados\n",
    "ALGUMAS POSSÍVEIS VERIFICAÇÕES:\n",
    "\n",
    "- Os meses precisam estar no intervalo: 1 <= meses <= 12\n",
    "- Os anos precisam estar no intervalo: 1900 <= ano <= 2016\n",
    "```python\n",
    "df_cln.loc[(df_cln['yearOfRegistration']<1900) | (df_cln['yearOfRegistration']>2016), 'yearOfRegistration'] = 1900\n",
    "```\n",
    "\n",
    "- Os preços precisam ser maiores que 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4:\n",
    "\n",
    "**Testes de Qualidade - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Utilize a biblioteca Great Expectations para criar testes de qualidade automatizados que verifiquem as expectativas definidas para os dados da camada \"silver\".\n",
    "   - Desenvolva testes que assegurem que os dados da camada \"silver\" atendam às regras de negócios e aos requisitos de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 5:\n",
    "\n",
    "**Transformação de Dados com dbt - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Utilize a ferramenta dbt para criar a camada \"silver\" de dados, realizando transformações e preparando os dados da camada em questão.\n",
    "   - Mantenha um controle de versão dos modelos dbt relacionados à camada \"silver\" e automatize a execução das transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 6:\n",
    "\n",
    "**Armazenamento de Dados em PostgreSQL - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Armazene os dados da camada \"silver\" no mesmo banco de dados PostgreSQL.\n",
    "   - Estabeleça conexões entre o dbt e o PostgreSQL para carregar os dados transformados da camada \"silver\" no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 7:\n",
    "\n",
    "**Validação de Expectativas com Great Expectations - Camada Silver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Implemente validações adicionais usando Great Expectations nas camadas de dados da camada \"silver\".\n",
    "   - Monitore a qualidade dos dados da camada \"silver\" após cada transformação e ajuste os testes de acordo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 8:\n",
    "\n",
    "**Transformação de Dados com dbt - Camada Gold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Utilize o dbt para criar a camada \"gold\" de dados, aplicando agregações especializadas, como médias de preços por propriedade, por período, e outras agregações especializadas.\n",
    "   - Mantenha um controle de versão dos modelos dbt relacionados à camada \"gold\" e automatize a execução das transformações.\n",
    "   - Armazene os dados da camada \"gold\" no mesmo banco de dados PostgreSQL, mantendo a estrutura de dados otimizada para consultas analíticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
